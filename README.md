T√≠tulo
GANs para s√≠ntesis de cuerpo humano en 3 modalidades: tabular (joints), imagen y 3D

Objetivo del proyecto
Entrenar modelos generativos (GAN) que produzcan muestras plausibles de cuerpo humano en tres representaciones:
A) Tabular: coordenadas 2D/3D de articulaciones (joints/keypoints).
B) Imagen: im√°genes ‚Äúhuman-like‚Äù (p. ej., render de esqueleto, heatmaps o silhouettes).
C) 3D: representaci√≥n 3D (nube de puntos / joints 3D / mesh simplificado).

Cada modalidad debe incluir:

Dataset grande (o derivado del tabular si no hay suficiente imagen/3D).

Entrenamiento de un generador y un discriminador adecuados.

Evaluaci√≥n cuantitativa con m√©tricas est√°ndar y un an√°lisis cualitativo (muestras).

Dataset recomendado y por qu√©
Opci√≥n principal: AMASS
AMASS unifica m√∫ltiples datasets de motion capture en un marco com√∫n, y se distribuye como par√°metros SMPL/SMPL+H y secuencias. Permite obtener joints 3D consistentes, y tambi√©n generar datos derivados (im√°genes y 3D).

Extracci√≥n de joints desde AMASS
Una pr√°ctica habitual es usar una ‚ÄúSMPL layer‚Äù para convertir par√°metros SMPL a joints y/o v√©rtices; repositorios que preparan datasets derivados desde AMASS (ej. HumanML3D) explican este flujo (extraer joints con SMPL, normalizar ejes, recortar secuencias, etc.).

Nota sobre TN(T)15 / NOMO3D
NOMO3D existe como dataset de escaneos 3D para antropometr√≠a, pero es mucho m√°s peque√±o que AMASS y no est√° pensado como gran corpus generativo.
(Para un trabajo de GAN con muchas muestras, AMASS suele ser m√°s viable.)

Qu√© vamos a generar exactamente (definiciones operativas)
Para evitar ambig√ºedad, fijamos ‚Äútargets‚Äù concretos por modalidad:

3.1 Tabular (joints)
Formato recomendado por frame:

J = 22 o 24 joints (seg√∫n SMPL/SMPL-X; elegir uno y mantenerlo fijo)

3D: (J, 3). Opcional 2D: proyectar despu√©s.

Normalizaci√≥n: centrar pelvis en (0,0,0), alinear el eje vertical, escalar por altura aproximada o longitud promedio de huesos.

Salida del generador:

Un frame (pose est√°tica) o una secuencia corta T frames.
Sugerencia: empezar por pose est√°tica (simplifica mucho).

3.2 Imagen
Dos alternativas v√°lidas; elegid una y mantenedla:
A) ‚ÄúSkeleton render‚Äù: renderizar el esqueleto como l√≠neas/puntos en un canvas (p. ej. 256√ó256). Se deriva del tabular y por tanto es ‚Äúdataset grande‚Äù.
B) Heatmaps por joint (multi-canal), luego convertir a RGB para la GAN (menos est√°ndar).

Recomendaci√≥n: A) skeleton render. Es f√°cil, reproducible y est√° alineado con ‚Äúsi no hay dataset grande de im√°genes, derivarlo del tabular‚Äù.

3.3 3D
Tres opciones, de m√°s f√°cil a m√°s compleja:
A) Joints 3D como ‚Äúpoint cloud‚Äù peque√±a (J puntos). (M√°s f√°cil; similar a tabular pero tratado como set).
B) Submuestreo de v√©rtices SMPL a N puntos (point cloud de superficie). (M√°s realista; requiere SMPL layer).
C) Mesh completo (m√°s pesado; no recomendado para un primer proyecto).

Recomendaci√≥n: B si el tiempo da, si no A. Para point clouds se eval√∫a con Chamfer/EMD/F-score t√≠picos; para joints, adem√°s plausibilidad cinem√°tica.

Modelos (arquitecturas m√≠nimas)
4.1 Tabular GAN (MLP-GAN)

Generator G(z): MLP que mapea z‚ààR^d ‚Üí vector joints (J*3).

Discriminator D(x): MLP que clasifica real/fake.

Loss: WGAN-GP o hinge loss (m√°s estable que GAN vanilla).

4.2 Image GAN (CNN-GAN)

DCGAN / ResNet GAN (seg√∫n nivel).

Entrada: ruido z; salida: imagen 256√ó256 (o 128√ó128).

Si us√°is skeleton render, las im√°genes son binarias o casi binarias; considerad:

salida con tanh y luego umbral para visualizar, pero entrenar con valores continuos.

4.3 3D GAN (Point Cloud GAN)

Generator: MLP ‚Üí (N,3) con reshape, o FoldingNet-style; simplificado.

Discriminator: PointNet-like (MLP por punto + maxpool global) para clasificar real/fake.
Esta familia (PointNet para sets) es est√°ndar para tratar nubes de puntos. En surveys de pose/point-cloud se discuten pipelines basados en PointNet.

M√©tricas de evaluaci√≥n (m√≠nimo viable + recomendadas)
La evaluaci√≥n ‚Äúde plausibilidad‚Äù en generativo no se limita a error contra GT (porque no hay correspondencia 1:1), as√≠ que proponemos m√©tricas de distribuci√≥n + m√©tricas biomec√°nicas.

5.1 Tabular (joints)
Distribuci√≥n:

MMD (Maximum Mean Discrepancy) entre distribuci√≥n real y generada (sobre vectores joints normalizados).

k-NN two-sample test (opcional).

Plausibilidad geom√©trica/cinem√°tica:

Bone Length Consistency: error relativo de longitudes de huesos respecto a estad√≠sticos del dataset (media/desviaci√≥n).

Joint Angle Limits: penalizar √°ngulos fuera de rangos (si defin√≠s cinem√°tica).

KCS (Kinematic Chain Space) / medidas de consistencia de cadena cinem√°tica (si quer√©is algo ‚Äúde paper‚Äù).

M√©tricas est√°ndar en pose (para referenciar en memoria del trabajo):
MPJPE y PA-MPJPE son m√©tricas est√°ndar en evaluaci√≥n de pose 3D (aunque son m√°s naturales cuando hay correspondencia con GT).

Si quer√©is citar ‚Äúm√©tricas de plausibilidad f√≠sica‚Äù m√°s modernas:
Hay trabajos que proponen m√©tricas espec√≠ficas de plausibilidad/estabilidad f√≠sica para poses 3D.

5.2 Imagen

FID (Fr√©chet Inception Distance) entre im√°genes reales (render del dataset) y generadas.

Precision/Recall para GANs (opcional, si ten√©is implementaciones).

5.3 3D (point clouds)

Chamfer Distance (CD) entre sets reales y generados (por matching aproximado).

Earth Mover‚Äôs Distance (EMD) si N es peque√±o y el c√≥mputo lo permite.

F-score a umbral œÑ (para proximidad entre nubes).

Estructura del repositorio
/README.md
/data/
/raw/ (AMASS u otros; NO versionar en git)
/processed/
tabular_joints.npz
images_skeleton/
pointclouds/
/src/
/data/
download_instructions.md
preprocess_amass_to_joints.py
render_skeleton_images.py
build_pointclouds.py
/models/
tabular_gan.py
image_gan.py
pointcloud_gan.py
/eval/
eval_tabular.py
eval_image_fid.py
eval_3d_cd_emd.py
/utils/
metrics.py
viz.py
/notebooks/ (opcionales)
/reports/
figures/
results.json
final_report.md

Pasos globales (checklist)
Paso 0. Entorno

Python 3.10+

PyTorch (o TF, pero que sea consistente)

Librer√≠as: numpy, scipy, matplotlib, tqdm, opencv (para renders), torchmetrics (si aplica), etc.

Si us√°is SMPL/SMPL-X: instalar dependencia y colocar modelos (seg√∫n licencia).

Paso 1. Dataset

Descargar AMASS (aceptar licencias) y organizar en /data/raw/amass/.

Documentar exactamente qu√© subconjuntos us√°is (nombres y tama√±o).

Paso 2. Preprocesado com√∫n

Convertir par√°metros SMPL ‚Üí joints 3D (Jx3) por frame.

Normalizar poses (root-centric, escala, orientaci√≥n).

Guardar en /data/processed/tabular_joints.npz.

Paso 3. Derivados

Renderizar skeleton images desde joints ‚Üí /data/processed/images_skeleton/.

Crear point clouds (N puntos) desde v√©rtices SMPL o desde joints ‚Üí /data/processed/pointclouds/.

Paso 4. Entrenar 3 GANs

Tabular GAN (MLP-GAN)

Image GAN (DCGAN/ResNetGAN)

3D GAN (PointNet discriminator + generator)

Paso 5. Evaluaci√≥n

Tabular: MMD + plausibilidad (huesos/√°ngulos) + visualizaciones

Imagen: FID + grid de samples

3D: Chamfer/EMD/F-score + visualizaci√≥n 3D (matplotlib o open3d)

Paso 6. Entrega

README + scripts reproducibles

Resultados (json/csv) + figuras

Conclusiones: qu√© funciona, qu√© no, y por qu√©.

Divisi√≥n en 4 participantes (pasos exactos por persona)

Persona 1 ‚Äî ‚ÄúData Lead + Tabular GAN‚Äù
Objetivo: dejar listo AMASS‚Üíjoints y entrenar Tabular GAN con evaluaci√≥n de plausibilidad.

Descargar AMASS y documentar licencias + subconjuntos usados.

Implementar preprocess_amass_to_joints.py:

Cargar secuencias

Extraer joints 3D con SMPL layer

Normalizar (pelvis al origen, orientaci√≥n, escala)

Guardar npz/hdf5 con splits train/val/test

Implementar tabular_gan.py:

G y D MLP

WGAN-GP (o hinge)

logging de p√©rdidas + samples

Implementar eval_tabular.py:

MMD real vs fake

Bone length statistics (mean/std) y ‚Äúbone length error‚Äù en generados

Visualizaci√≥n simple (esqueleto 3D por matplotlib)

Entregables de Persona 1:

/src/data/preprocess_amass_to_joints.py

/src/models/tabular_gan.py

/src/eval/eval_tabular.py

/reports/figures/tabular_samples.png + results_tabular.json

Persona 2 ‚Äî ‚ÄúImage Lead (dataset derivado + CNN GAN + FID)‚Äù
Objetivo: construir dataset de im√°genes a partir de joints y entrenar GAN de im√°genes.

Implementar render_skeleton_images.py:

Entrada: joints normalizados

Salida: PNG 128√ó128 o 256√ó256 con skeleton dibujado (l√≠neas + puntos)

Guardar train/val/test en carpetas

Implementar image_gan.py (DCGAN/ResNet GAN):

Entrenamiento estable

Guardar checkpoints

Implementar eval_image_fid.py:

Calcular FID entre reales (renders) y generadas

Generar grids de muestras

Entregables de Persona 2:

/src/data/render_skeleton_images.py

/src/models/image_gan.py

/src/eval/eval_image_fid.py

/reports/figures/image_samples.png + results_image.json

Persona 3 ‚Äî ‚Äú3D Lead (point clouds + GAN + Chamfer/EMD)‚Äù
Objetivo: construir representaci√≥n 3D y entrenar GAN 3D.

Elegir representaci√≥n:

Opci√≥n recomendada: samplear N puntos de superficie SMPL (si SMPL layer disponible)

Alternativa: usar joints como point cloud de tama√±o J

Implementar build_pointclouds.py:

Generar point clouds normalizadas (centradas, escala consistente)

Guardar en formato npz

Implementar pointcloud_gan.py:

Discriminador tipo PointNet (per-point MLP + maxpool)

Generador MLP que produce Nx3

Implementar eval_3d_cd_emd.py:

Chamfer Distance (m√≠nimo)

EMD (opcional) y F-score (opcional)

Visualizaci√≥n de nubes (antes/despu√©s)

Entregables de Persona 3:

/src/data/build_pointclouds.py

/src/models/pointcloud_gan.py

/src/eval/eval_3d_cd_emd.py

/reports/figures/pc_samples.png + results_3d.json

Persona 4 ‚Äî ‚ÄúIntegraci√≥n + Reproducibilidad + Reporte‚Äù
Objetivo: que todo sea ejecutable, comparable y presentable.

Definir est√°ndar de splits, seeds y rutas (config.py o YAML).

Crear scripts de ejecuci√≥n:

train_tabular.sh / train_image.sh / train_3d.sh

eval_all.sh que genere /reports/results.json

Unificar logging (tensorboard o CSV).

Redactar final_report.md:

Motivaci√≥n y related work corto

Descripci√≥n de datos y preprocesado

Arquitecturas y p√©rdidas

Resultados cuantitativos y cualitativos

Ablaciones simples (por ejemplo: WGAN-GP vs GAN vanilla en tabular)

Revisar que README refleje exactamente c√≥mo reproducir.

Entregables de Persona 4:

/src/configs/*.yaml + scripts de run

/reports/final_report.md + results.json consolidado

Checklist de reproducibilidad

Cronograma sugerido (compacto)
Semana 1: dataset + preprocesado tabular listo (Persona 1) y renderer de skeleton (Persona 2).
Semana 2: entrenos base tabular + imagen; preparar 3D pipeline.
Semana 3: 3D GAN + m√©tricas; estabilizaci√≥n y comparaci√≥n.
Semana 4: reporte, figuras, limpieza del repo y reproducibilidad.

Preguntas que necesito que confirmes (solo para cerrar ambig√ºedades del enunciado)

¬øVuestro profesor exige expl√≠citamente que sea ‚ÄúGAN‚Äù en las 3 partes, o acepta ‚Äúgenerativo‚Äù en general (VAE/diffusion) mientras haya generaci√≥n?

¬øLa parte tabular debe generar ‚Äúposes est√°ticas‚Äù (un frame) o ‚Äúsecuencias‚Äù (varios frames)?

En 3D, ¬øos aceptan ‚Äújoints 3D‚Äù como 3D, o tiene que ser ‚Äúnube de puntos/mesh‚Äù de superficie?

Si me respondes esas 3, te ajusto el README a lo que os punt√∫e mejor (sin cambiar el enfoque general).







# 3D Body Generation & Mass Estimation using GANs üèÉ‚Äç‚ôÇÔ∏èüìä

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?logo=pytorch&logoColor=white)
![SMPL](https://img.shields.io/badge/Model-SMPL--X-orange)

Este repositorio contiene la implementaci√≥n de una **Red Generativa Antag√≥nica (GAN)** dise√±ada para la reconstrucci√≥n de cuerpos humanos en 3D y la estimaci√≥n de masa corporal a partir de datos antropom√©tricos m√≠nimos.

## üéØ Objetivo del Proyecto

El reto principal consiste en generar representaciones corporales realistas (nubes de puntos de 6890 v√©rtices) utilizando √∫nicamente un **vector de 10 par√°metros tabulares**. 

Utilizamos el dataset **AMASS** para entrenar un modelo que aprenda la distribuci√≥n real de las formas humanas, permitiendo que el generador "sintetice" cuerpos que pasen el Test de Turing frente a un discriminador experto.

## üõ†Ô∏è Arquitectura Propuesta

El sistema se divide en tres bloques principales:

1.  **Generador (MLP):** Recibe par√°metros latentes y devuelve el vector de masa/forma (10 puntos clave).
2.  **Pipeline Tabular-to-Body:** Mapea el vector generado a una malla SMPL de 6890 puntos.
3.  **Discriminador:** Una dos tres
